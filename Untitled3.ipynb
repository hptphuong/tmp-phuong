{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "learning_rate=0.1\n",
    "num_steps=8000\n",
    "batch_size = 100\n",
    "displays_step=100\n",
    "\n",
    "# Network parameters\n",
    "\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 =256\n",
    "num_inputs =784\n",
    "num_classifies = 10\n",
    "\n",
    "X=tf.placeholder(\"float\",[None,num_inputs])\n",
    "Y=tf.placeholder(\"float\",[None,num_classifies])\n",
    "weight={\n",
    "    'h1': tf.Variable(tf.random_normal([num_inputs,n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2,num_classifies]))\n",
    "}\n",
    "bias={\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classifies]))\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "def neural_net(x):\n",
    "    layer1=tf.add(tf.matmul(x,weight['h1']),bias['b1'])\n",
    "    layer2=tf.add(tf.matmul(layer1,weight['h2']),bias['b2'])\n",
    "    out_layer=tf.add(tf.matmul(layer2,weight['out']),bias['out'])\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = neural_net(X)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y))\n",
    "\n",
    "\n",
    "correct_op = tf.equal(tf.argmax(logits,1),tf.argmax(Y,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_op,tf.float32))\n",
    "\n",
    "train =tf.train.AdamOptimizer(learning_rate).minimize(loss_op)\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, with loss 8252.791016 accuracy  0.43\n",
      "step 100, with loss 763.579163 accuracy  0.84\n",
      "step 200, with loss 49.271416 accuracy  0.93\n",
      "step 300, with loss 152.026306 accuracy  0.81\n",
      "step 400, with loss 14.680542 accuracy  0.91\n",
      "step 500, with loss 98.231483 accuracy  0.84\n",
      "step 600, with loss 36.374805 accuracy  0.92\n",
      "step 700, with loss 95.795486 accuracy  0.83\n",
      "step 800, with loss 70.436554 accuracy  0.90\n",
      "step 900, with loss 168.773041 accuracy  0.82\n",
      "step 1000, with loss 117.933006 accuracy  0.82\n",
      "step 1100, with loss 114.010452 accuracy  0.84\n",
      "step 1200, with loss 96.910782 accuracy  0.84\n",
      "step 1300, with loss 83.317635 accuracy  0.82\n",
      "step 1400, with loss 115.126183 accuracy  0.86\n",
      "step 1500, with loss 93.478088 accuracy  0.86\n",
      "step 1600, with loss 101.969948 accuracy  0.87\n",
      "step 1700, with loss 49.132004 accuracy  0.84\n",
      "step 1800, with loss 18.331060 accuracy  0.94\n",
      "step 1900, with loss 82.977097 accuracy  0.88\n",
      "step 2000, with loss 70.143425 accuracy  0.87\n",
      "step 2100, with loss 183.261902 accuracy  0.87\n",
      "step 2200, with loss 36.943985 accuracy  0.89\n",
      "step 2300, with loss 159.981293 accuracy  0.84\n",
      "step 2400, with loss 216.065125 accuracy  0.86\n",
      "step 2500, with loss 5246.583008 accuracy  0.85\n",
      "step 2600, with loss 3008.803711 accuracy  0.86\n",
      "step 2700, with loss 1262.681152 accuracy  0.89\n",
      "step 2800, with loss 966.790771 accuracy  0.89\n",
      "step 2900, with loss 275.551392 accuracy  0.90\n",
      "step 3000, with loss 229.168945 accuracy  0.93\n",
      "step 3100, with loss 115.773651 accuracy  0.86\n",
      "step 3200, with loss 112.310410 accuracy  0.89\n",
      "step 3300, with loss 79.650887 accuracy  0.90\n",
      "step 3400, with loss 45.354374 accuracy  0.89\n",
      "step 3500, with loss 22.371138 accuracy  0.95\n",
      "step 3600, with loss 18.463022 accuracy  0.91\n",
      "step 3700, with loss 69.192894 accuracy  0.86\n",
      "step 3800, with loss 29.540930 accuracy  0.92\n",
      "step 3900, with loss 35.286022 accuracy  0.94\n",
      "step 4000, with loss 61.614765 accuracy  0.94\n",
      "step 4100, with loss 90.763206 accuracy  0.81\n",
      "step 4200, with loss 57.561573 accuracy  0.84\n",
      "step 4300, with loss 16.799280 accuracy  0.92\n",
      "step 4400, with loss 49.652515 accuracy  0.88\n",
      "step 4500, with loss 16.379389 accuracy  0.91\n",
      "step 4600, with loss 44.281792 accuracy  0.88\n",
      "step 4700, with loss 54.251518 accuracy  0.95\n",
      "step 4800, with loss 35.645741 accuracy  0.91\n",
      "step 4900, with loss 49.037663 accuracy  0.91\n",
      "step 5000, with loss 54.958824 accuracy  0.89\n",
      "step 5100, with loss 56.821957 accuracy  0.85\n",
      "step 5200, with loss 81.593079 accuracy  0.88\n",
      "step 5300, with loss 167.663757 accuracy  0.84\n",
      "step 5400, with loss 24.095291 accuracy  0.96\n",
      "step 5500, with loss 195.274109 accuracy  0.85\n",
      "step 5600, with loss 112.411270 accuracy  0.82\n",
      "step 5700, with loss 639.253296 accuracy  0.79\n",
      "step 5800, with loss 7150.586426 accuracy  0.78\n",
      "step 5900, with loss 1261.602539 accuracy  0.90\n",
      "step 6000, with loss 2102.985352 accuracy  0.90\n",
      "step 6100, with loss 830.178040 accuracy  0.88\n",
      "step 6200, with loss 175.733536 accuracy  0.93\n",
      "step 6300, with loss 185.889709 accuracy  0.93\n",
      "step 6400, with loss 145.762650 accuracy  0.96\n",
      "step 6500, with loss 182.237885 accuracy  0.86\n",
      "step 6600, with loss 131.824081 accuracy  0.94\n",
      "step 6700, with loss 98.340927 accuracy  0.87\n",
      "step 6800, with loss 150.601166 accuracy  0.88\n",
      "step 6900, with loss 110.843529 accuracy  0.89\n",
      "step 7000, with loss 114.385071 accuracy  0.87\n",
      "step 7100, with loss 36.490025 accuracy  0.95\n",
      "step 7200, with loss 32.827431 accuracy  0.92\n",
      "step 7300, with loss 39.960629 accuracy  0.89\n",
      "step 7400, with loss 92.796799 accuracy  0.86\n",
      "step 7500, with loss 55.091873 accuracy  0.96\n",
      "step 7600, with loss 73.711700 accuracy  0.86\n",
      "step 7700, with loss 16.396568 accuracy  0.96\n",
      "step 7800, with loss 44.533447 accuracy  0.90\n",
      "step 7900, with loss 47.947178 accuracy  0.93\n",
      "step 8000, with loss 107.691826 accuracy  0.92\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1,num_steps+1):\n",
    "#         print (step)\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "        sess.run(train,feed_dict={X:batch_x,Y:batch_y})\n",
    "        if(step % displays_step ==0 or step ==1):\n",
    "            print(\"step %d,\" % step,\"with loss %5f\" %sess.run(loss_op,feed_dict={X:batch_x,Y:batch_y}), \"accuracy %5.2f\" %sess.run(accuracy,feed_dict={X:batch_x,Y:batch_y}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Using some of TensorFlow higher-level wrappers (tf.estimators, tf.layers, tf.metrics, ...), you can check 'neural_network_raw' example for a raw, and more detailed TensorFlow implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "learning_rate=0.1\n",
    "num_steps=8000\n",
    "batch_size = 100\n",
    "displays_step=100\n",
    "\n",
    "# Network parameters\n",
    "\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 =256\n",
    "num_inputs =784\n",
    "num_classifies = 10\n",
    "\n",
    "# X=tf.placeholder(\"float\",[None,num_inputs])\n",
    "# Y=tf.placeholder(\"float\",[None,num_classifies])\n",
    "# weight={\n",
    "#     'h1': tf.Variable(tf.random_normal([num_inputs,n_hidden_1])),\n",
    "#     'h2': tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "#     'out': tf.Variable(tf.random_normal([n_hidden_2,num_classifies]))\n",
    "# }\n",
    "# bias={\n",
    "#     'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "#     'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "#     'out': tf.Variable(tf.random_normal([num_classifies]))\n",
    "# }\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classifies = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.train.images},y=mnist.train.labels,\n",
    "    batch_size=batch_size,shuffle=False,num_epochs=None)\n",
    "# input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#     x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "#     batch_size=batch_size, num_epochs=None, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Neural network\n",
    "\n",
    "def neural_net(x_dict):\n",
    "    x=x_dict['images']\n",
    "    layer1=tf.layers.dense(x,n_hidden_1)\n",
    "    layer2=tf.layers.dense(layer1,n_hidden_2)\n",
    "    out_layer=tf.layers.dense(layer2,num_classifies)\n",
    "    return out_layer\n",
    "# def neural_net(x_dict):\n",
    "#     # TF Estimator input is a dict, in case of multiple inputs\n",
    "#     x = x_dict['images']\n",
    "#     # Hidden fully connected layer with 256 neurons\n",
    "#     layer_1 = tf.layers.dense(x, n_hidden_1)\n",
    "#     # Hidden fully connected layer with 256 neurons\n",
    "#     layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n",
    "#     # Output fully connected layer with a neuron for each class\n",
    "#     out_layer = tf.layers.dense(layer_2, num_classifies)\n",
    "#     return out_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model function ( TSF estimator)\n",
    "\n",
    "# def model_fn(features,labels,mode):\n",
    "#     logits=neural_net(features)   \n",
    "#     pred_classes = tf.argmax(logits,1)\n",
    "    \n",
    "#     pred_proba = tf.nn.softmax(logits)\n",
    "    \n",
    "    \n",
    "# #     loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=tf.cast(labels,tf.int32)))\n",
    "#     loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "#         logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "#     train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_op,global_step=tf.train.get_global_step())\n",
    "    \n",
    "#     acc_op = tf.metrics.accuracy(labels=labels,predictions=pred_classes)\n",
    "#     estim_specf=tf.estimator.EstimatorSpec(\n",
    "#         mode=mode,\n",
    "#         predictions=pred_classes,\n",
    "#         loss =loss_op,\n",
    "#         train_op=train_op,\n",
    "#         eval_metric_ops={'accuracy':acc_op}\n",
    "#     )\n",
    "#     return estim_specf\n",
    "    \n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # Build the neural network\n",
    "    logits = neural_net(features)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        print(\">>>>>>>>>>tf.estimator.ModeKeys.PREDICT\")\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "#     if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "#         print(\">>>>>>>>>tf.estimator.ModeKeys.TRAIN\")\n",
    "        \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "#     if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "#         print(\">>>>>>>>>tf.estimator.ModeKeys.TRAIN\")\n",
    "#         return tf.estimator.EstimatorSpec(mode, train_op=train_op,loss=loss_op) \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\PHUONG~1\\AppData\\Local\\Temp\\tmp9hojil29\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\PHUONG~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9hojil29', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000000FB6CA90>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\PHUONG~1\\AppData\\Local\\Temp\\tmp9hojil29\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.42352, step = 1\n",
      "INFO:tensorflow:global_step/sec: 126.904\n",
      "INFO:tensorflow:loss = 0.499081, step = 101 (0.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.889\n",
      "INFO:tensorflow:loss = 0.529096, step = 201 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.699\n",
      "INFO:tensorflow:loss = 0.162506, step = 301 (0.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.205\n",
      "INFO:tensorflow:loss = 0.367799, step = 401 (0.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.865\n",
      "INFO:tensorflow:loss = 0.446446, step = 501 (0.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.931\n",
      "INFO:tensorflow:loss = 0.439817, step = 601 (0.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.228\n",
      "INFO:tensorflow:loss = 0.351705, step = 701 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.511\n",
      "INFO:tensorflow:loss = 0.193083, step = 801 (0.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.986\n",
      "INFO:tensorflow:loss = 0.552262, step = 901 (0.720 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\PHUONG~1\\AppData\\Local\\Temp\\tmp9hojil29\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.136837.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0xfb6c748>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn,steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-16-03:58:08\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\PHUONG~1\\AppData\\Local\\Temp\\tmpzfwjz47t\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-16-03:58:08\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9144, global_step = 1000, loss = 0.294185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.91439998, 'global_step': 1000, 'loss': 0.29418531}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_fn=tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images},y= mnist.test.labels,batch_size=batch_size, shuffle=False)\n",
    "model.evaluate(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>tf.estimator.ModeKeys.PREDICT\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\PHUONG~1\\AppData\\Local\\Temp\\tmp9hojil29\\model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "n_images = 4\n",
    "# Get images from test set\n",
    "test_images = mnist.test.images[:n_images]\n",
    "# Prepare the input data\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': test_images}, shuffle=False)\n",
    "# Use the model to predict the images class\n",
    "preds = list(model.predict(input_fn))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
